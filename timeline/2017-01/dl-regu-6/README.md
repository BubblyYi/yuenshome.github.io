[![header](../../../assets/header24.jpg)](https://yuenshome.github.io)

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>

# 深度学习正则化系列6：参数绑定和参数共享、稀疏表示、Bagging和其它集成方法

《Deep Learning》Chapter 7
Regularization for Deep Learning
翻译水平有限，如有错误请留言，不胜感激！

[toc]
<h1>7.9 参数绑定与参数共享</h1>
本章到目前为止，当讨论给参数加入限制或惩罚时，我们总是限定在固定的区域或点中。例如， $L^2$ 正则化（或权重衰减）惩罚模型参数从参数的固定值零的偏离开始。然而，有时可能需要另外能表达关于模型参数合适值的先验知识。有时可能不知道参数应该采用什么值，但是知道从领域和模型架构的知识，这其中应该有一些模型参数之间的依赖关系。

我们经常想要表达的常见类型的依赖性是某些参数应当彼此接近。考虑以下情况：我们有两个模型执行相同的分类任务（具有相同的类集合），但具有稍微不同的输入数据分布。正式地，我们有参数 $w^{(A)}$ 的模型A和具有参数 $w^{(B)}$ 的模型B，两个模型将输入映射到两个不同但相关的输出： $\hat{y}^{(A)} = f(w^{(A)}, x)$ 和 $\hat{y}^{(B)} = g(w^{(B)}, x)$ 。

让我们假设任务是相似的（可能具有类似的输入和输出分布），我们认为模型参数应该彼此接近： $\forall i, w_i^{(A)}$ 应该接近 $w_i^{(B)}$ 。我们可以通过正则化利用这些信息。具体来说，可以使用以下形式的参数规范惩罚： $\Omega (w^{(A)}, w^{(B)}) = || w^{(A)} - w^{(B)} ||_2^{2}$ 。这里我们使用了 $L^2$ 惩罚，但其它选择也是可能的。<!--more-->

这种方法是由Lasserre等人（2006）提出，将一个模型的参数正则化，使用监督学习的范式训练为分类器，接近另一个使用无监督范式（捕获观察输入数据的分布）训练的模型的参数。构造体系结构使得分类器模型中的许多参数可以与无监督模型中的相应参数配对。

虽然参数范数惩罚是将参数正则化为（译注：让二者模型）彼此接近的一种方式，但更常用的方式是使用约束：迫使参数集相等，这种正则化方法通常被称为<strong>参数共享（parameter sharing）</strong>，因为我们将各种模型或模型组件解释为共享所有参数集合中的其中一组唯一的参数。参数共享在正则化上要关闭的参数（通过范数惩罚）的显着优点（A signiﬁcant advantage of parameter sharing over regularizing the parameters to be close (via a norm penalty)）是只需要将所有权重参数（中唯一集合）的子集存储在存储器中，在某些模型中如卷积神经网络，参数共享可以使模型的内存占用显着减少。
<h2>卷积神经网络</h2>
到目前为止，使用最流行且最被广泛使用的参数共享是应用于计算机视觉的卷积神经网络（CNNs）。

自然图像具有对于平移不变等的许多统计特性。例如，如果猫的照片向右平移一个像素，则猫的照片仍然是猫的照片。卷积神经网络通过在图像上多个位置共享参数来考虑此属性。在输入中的不同位置计算相同的特征（具有相同权重的隐含单元）。这意味着我们可以使用相同的猫检测器找到猫，无论猫出现在图像中的第 $i$ 列还是第 $i + 1$ 列。

参数共享可使卷积神经网络显著减少模型参数的数量，并在不需要增加训练数据的前提下可显著增加网络规模（译注：深度或宽度）。参数共享策略仍然是将领域知识考虑到网络架构中的最好案例之一。

卷积神经网络的更多细节将在第9章讨论。
<h1>7.10 稀疏表示</h1>
权重衰减通过直接对模型参数施加惩罚来起作用。另一个策略是在神经网络中的单元激活施加惩罚，鼓励它们的激活变得稀疏的。这间接地对模型参数施加了复杂的惩罚。

我们已经讨论了（在7.1.2节中） $L^1$ 惩罚如何诱导稀疏参数化——这意味着许多参数变为零（或接近零）。另一方面，表示稀疏性描述了一种数据表示，这是一种许多元素为零（或接近零）的表示。这种区别的简化表示可以在线性回归中描述为：

$$
\begin{align}
\underset{y ~\in~ \Re^m}{
\begin{bmatrix}
18 \\ 5 \\ 15 \\ -9 \\ -3
\end{bmatrix}} =
\underset{A ~\in~ \Re^{m \times n}}{
\begin{bmatrix}
4 &amp; 0 &amp; 0 &amp; -2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; -1 &amp; 0 &amp; 3 &amp; 0 \\
0 &amp; 5 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 &amp; -1 &amp; 0 &amp; -4 \\
1 &amp; 0 &amp; 0 &amp; 0 &amp; -5 &amp; 0
\end{bmatrix}}
\underset{x ~\in~ \Re^n}{
\begin{bmatrix}
2 \\ 3\\ -2\\ -5 \\ 1 \\ 4
\end{bmatrix} }\\
\underset{y ~\in~ \Re^m}{
\begin{bmatrix}
-14 \\ 1 \\ 19 \\ 2 \\ 23
\end{bmatrix}} =
\underset{B ~\in~ \Re^{m \times n}}{
\begin{bmatrix}
3 &amp; -1 &amp; 2 &amp; -5 &amp; 4 &amp; 1 \\
4 &amp; 2 &amp; -3 &amp; -1 &amp; 1 &amp; 3 \\
-1 &amp; 5 &amp; 4 &amp; 2 &amp; -3 &amp; -2 \\
3 &amp; 1 &amp; 2 &amp; -3 &amp; 0 &amp; -3 \\
-5 &amp; 4 &amp; -2 &amp; 2 &amp; -5 &amp; -1
\end{bmatrix}}
\underset{h \in \Re^n}{
\begin{bmatrix}
0 \\ 2 \\ 0 \\ 0 \\ -3 \\ 0
\end{bmatrix} }
\end{align}
$$

在第一个表达式中，我们有一个稀疏参数化线性回归模型的例子。在第二个中，我们使用数据x的稀疏表示h进行线性回归。 也就是说，$h$ 是 $x$ 的函数，在某种意义上， $x$ 表示存在于 $x$ 中的信息，但是使用稀疏向量。

表示正则化通过我们在参数正则化中使用的相同种类的机制来完成。

通过向损失函数 $J$ 添加对表示的规范惩罚来执行表示的规范惩罚正规化。 该惩罚被表示为 $\Omega$ 。 如前所述，我们用 $\widetilde{J}$ 表示正则化损失函数：

$$
\widetilde{J} (\theta; X, y) = J(\theta; X, y) + \alpha \Omega (h)
$$

其中 $\alpha \in [0, \infty)$ 表示加权范数惩罚项的相对贡献，较大的 $\alpha$ 值对应于正则化项的加强。

正如参数上的 $L^1$ 正则诱发参数稀疏性一样，对表示元素上的 $L^1$ 正则也会引起表示稀疏性： $\Omega (h) = ||h||_1 = \sum_i |h_i|$ 。当然， $L^1$ 正则只是可以导致稀疏表示的正则方法的一个选择。其他的包括来自学生提出的正则（Olshausen和Field，1996；Bergstra，2011）和KL散度正则（Larochelle和Bengio，2008），对元素被限制在单元间隔的情形特别有用。Lee等人（2008）和Goodfellow等人（2009）都提出了基于几个样本 $\frac{1}{m} \sum_i h^{(i)}$ 的平均激活进行正则化，让其接近某个目标值的策略，例如每个元素都为 $0.01$ 的向量。

其他方法获得具有对激活值的硬约束的表示稀疏性。 例如，正交匹配追踪（orthogonal matching pursuit，Pati等人，1993）用表示h对输入x进行编码，来解决约束优化问题。

$$
\arg_{h, ||h||_0 &lt; k} \min ||x - Wh||^2,
$$

其中 $||h||_0$ 是 $h$ 中非零项的数目。 当 $W$ 被约束为正交时，这个问题可以被有效解决。此方法通常称为OMP-k， $k$ 值为允许的非零特征的数量。 Coates和Ng（2011）证明OMP-1可以是深层架构非常有效的特征提取器。

基本上任何具有隐藏单元的模型都可以被稀疏化。在本书中，我们将看到许多在各种情景中使用稀疏正则化的例子。
<h1>7.11 Bagging和其它集成方法</h1>
Bagging（bootstrap aggregating的简写）是一种通过组合几个模型来减少泛化误差的技术（Breiman，1994）。想法是分别训练几个不同的模型，然后让所有的模型投票输出测试示例的预测结果。 这是在机器学习称为模型平均的策略。采用这种策略的技术被称为集成方法（ensemble methods）。

模型平均能够有效的原因是不同的模型通常不会在测试集上的所有样本上产生相同的错误。

考虑一个集成 $k$ 个回归模型的例子。假设每个模型在每个样本上的误差是 $\epsilon_i$ ，误差服从零均值，方差为 $E[\epsilon_i^2] = v$ 且协方差为 $E[\epsilon_i \epsilon_j] = c$ 的多维正态分布。基于所有模型得到的集成模型的平均预测误差是 $\frac{1}{k} \sum_i \epsilon_i$ 。集成模型得到的预测器平方误差的期望是

$$
\begin{align}
E \Bigg[\Bigg(\frac{1}{k} \sum_i \epsilon_i \Bigg)^2\Bigg]
&amp; = \frac{1}{k^2} E \Bigg[\sum_i \Bigg(\epsilon_i^2 + \sum_{j \neq i} \epsilon_i \epsilon_j\Bigg)\Bigg], \\
&amp; = \frac{1}{k} v + \frac{k-1}{k} c .
\end{align}
$$

在误差完全相关且 $c = v$ 的情况下，均方误差减小到 $v$ ，因此模型平均根本不起作用。在误差完全不相关并且 $c = 0$ 的情况下，集成的预期平方误差仅为 $\frac{1}{k}v$ 。这意味着模型集成的预期平方误差随集成模型的模型数目而线性减小。换句话说，平均而言，集成模型的表现将至少与其所有模型中的任何一个一样好，并且因为每个模型有各自的误差，集合模型相比成员模型的表现得到显著的改善。

不同的集成方法以不同的方式构建模型集成。例如，集成的每个成员模型可以通过使用不同的算法或目标函数训练完全不同种类的模型来形成集成。Bagging是一种允许相同类型的模型、训练算法和目标函数被重复使用多次的方法。

<img class="aligncenter" src="http://yuenshome-wordpress.stor.sinaapp.com/uploads/2017/01/deeplearning_chapter7_figure7.5.png" alt="" width="725" height="363" />

<strong>图7.5：该图是bagging如何工作的卡通描述。假设在上面描述的数据集上训练一个数字8检测器，原始数据集包含数字8、6和9。假设我们做出两个不同的重采样数据集。Bagging训练过程是用替换抽样来构造数据集中的每个样本。第一个数据集忽略掉数字9的数据并用数字8替换。在此数据集上，检测器获知数字顶部的圈对应于8的部分。在第二个数据集上，我们用数字9的数据来替换数字6的数据。在这种情况下，检测器获知数字底部的小圈对应于数字8的部分。每个单独的分类规则是脆弱的，但是如果平均它们的输出，则检测器是鲁棒的，只有当数字8的两个圈同时存在时才实现最大的置信度。</strong>

具体来说，bagging涉及构建 $k$ 个不同的数据集。每个数据具有与原始数据集相同数量的样本，但每个数据集是通过从原始数据集中替换进行抽样构建的。这意味着有很大概率下，每个数据集都是原始数据集的一个子集，并且（如果在训练集中每次抽样原始数据集约 $\frac{2}{3}$ 样本）还包含若干（译注：与先前抽样得到的数据集）重复的样本。模型 $i$ 基于数据集 $i$ 训练。每个数据集中包括的样本之间的差异导致训练模型之间的差异。参见图7.5的例子。

神经网络被广泛地用在各种解决方案中，即使所有的模型在同一个数据集上训练，他们通常也可从模型平均中获益。随机权重初始化，随机选择小样本批量，超参数的差异或神经网络的非确定性实现的不同结果的差异，通常足以导致集成所采用的不同模型成员产生部分独立的错误。

模型平均是一种用于减少泛化误差的强大且可靠的方法。科学论文的基准算法通常不鼓励使用它，因为任何机器学习算法都可以增加计算和内存为代价从模型平均中获益。因此，基准通常使用单个模型。

机器学习竞赛中常用的策略就是通过使用在数十个模型上的模型平均的方法来获得结果。最近一个突出的例子是Netflix大奖赛中的第一名所使用的模型集成策略（Koren，2009）。

不是所有用于构建集成的技术可使集成后的模型比单个模型更加具有正则化（译注：意味着更低的泛化误差）。例如，称为boosting的技术（Freund和Schapire，1996b，a）可构建具有比单个模型更高容量的集成模型。Boosting已经应用于构建多个神经网络的集成（Schwenk和Bengio，1998），通过向集成模型中增量地添加不同的神经网络。Boosting也被应用于将单个神经网络解释为一个集成模型（Bengio等人，2006a），模型成员是在该单个神经网络逐步添加隐藏单元向一个完整神经网络构建的过程中形成的。
